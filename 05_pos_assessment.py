# -*- coding: utf-8 -*-
"""05-POS-Assessment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bq73XAtnRtCrDmxwdWeuC82BSuWraxTJ

___

<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>
___

# Parts of Speech Assessment

For this assessment we'll be using the short story [The Tale of Peter Rabbit](https://en.wikipedia.org/wiki/The_Tale_of_Peter_Rabbit) by Beatrix Potter (1902). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/14838.txt.utf-8).
"""

# RUN THIS CELL to perform standard imports:
import spacy
nlp = spacy.load('en_core_web_sm')
from spacy import displacy

nlp.pipeline

nlp.pipe_names

"""**1. Create a Doc object from the file `peterrabbit.txt`**<br>
> HINT: Use `with open('../TextFiles/peterrabbit.txt') as f:`
"""

with open("/content/The Tale of Peter Rabbit is a child.txt", "r") as file:
    text = file.read()
doc = nlp(text)

"""**2. For every token in the third sentence, print the token text, the POS tag, the fine-grained TAG tag, and the description of the fine-grained tag.**"""

# Enter your code here:
t_sent = list(doc.sents)[2]
for token in t_sent:
  print(f"Token: {token.text}")
  print(f"POS Tag: {token.pos_}")
  print(f"Fine-grained TAG: {token.tag_}")
  print(f"Description of Fine-grained TAG: {spacy.explain(token.tag_)}")
  print("-" * 20)

"""**3. Provide a frequency list of POS tags from the entire document**"""

from collections import Counter

pos_tag_counter = Counter()

# Iterate through all tokens in the document and count POS tags
for token in doc:
    pos_tag_counter[token.pos_] += 1
print("POS Tag Frequency List:")
for pos_tag, count in pos_tag_counter.items():
    print(f"{pos_tag}: {count}")

"""**4. CHALLENGE: What percentage of tokens are nouns?**<br>
HINT: the attribute ID for 'NOUN' is 91
"""

noun_count = sum(1 for token in doc if token.pos_ == "NOUN")

total_t = len(doc)
percentage_n = (noun_count/total_t)*100

print(f"Percentage of tokens that are nouns: {percentage_n:.2f}%")

"""**5. Display the Dependency Parse for the third sentence**"""

t_sent = list(doc.sents)[2]

print("Dependency Parse for the Third Sentence: ")

for token in t_sent:
  print(f"{token.text}-->{token.dep_}-->{token.head.text}")

"""**6. Show the first two named entities from Beatrix Potter's *The Tale of Peter Rabbit* **"""

named_entities = [(ent.text, ent.label_) for ent in doc.ents]
print("First Two Named Entities:")
for i, (text, label) in enumerate(named_entities[:2], start=1):
    print(f"{i}. Text: {text}, Label: {label}")

"""**7. How many sentences are contained in *The Tale of Peter Rabbit*?**"""

num_sentences = len(list(doc.sents))
print(f"The Tale of Peter Rabbit contains {num_sentences} sentences.")

"""**8. CHALLENGE: How many sentences contain named entities?**"""

num_sentences_with_entities = sum(1 for sent in doc.sents if any(ent for ent in sent.ents))

print(f"The Tale of Peter Rabbit contains {num_sentences_with_entities} sentences with named entities.")

"""**9. CHALLENGE: Display the named entity visualization for `list_of_sents[0]` from the previous problem**"""

sentences_with_entities = [sent for sent in doc.sents if any(ent for ent in sent.ents)]
if sentences_with_entities:
    first_sentence_with_entities = sentences_with_entities[0]
    displacy.render(first_sentence_with_entities, style="ent", jupyter=True)
else:
    print("No sentences with named entities found.")